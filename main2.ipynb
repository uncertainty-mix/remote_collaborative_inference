{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:29:18.276908Z",
     "start_time": "2025-01-11T10:29:18.272201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split, RandomSampler, Subset\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForImageClassification\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, OneCycleLR, ReduceLROnPlateau, StepLR\n",
    "import timm\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from timm.data.auto_augment import rand_augment_transform\n",
    "import io\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import time"
   ],
   "id": "1a47e97aa933f3fb",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 运行前需要填入这两项\n",
    "openai_api_rul = \"\"\n",
    "openai_api_key = \"\""
   ],
   "id": "3b9e10282405323c"
  },
  {
   "cell_type": "code",
   "id": "64c2932796bc1e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T01:51:05.695266Z",
     "iopub.status.busy": "2024-12-28T01:51:05.694662Z",
     "iopub.status.idle": "2024-12-28T01:51:05.702735Z",
     "shell.execute_reply": "2024-12-28T01:51:05.701688Z",
     "shell.execute_reply.started": "2024-12-28T01:51:05.695208Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:09.600221Z",
     "start_time": "2025-01-11T08:54:05.310341Z"
    }
   },
   "source": [
    "seeds = [0,0,0,0,0]\n",
    "# seeds = [0,0,0,0,0]\n",
    "eval_seed = 0\n",
    "\n",
    "train_augmentations = [\n",
    "    torchvision.transforms.Compose([\n",
    "        rand_augment_transform(\n",
    "            config_str='rand-m7-mstd0.5',\n",
    "            hparams=dict()\n",
    "        ) \n",
    "    ]),\n",
    "    \n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(), \n",
    "        torchvision.transforms.RandomErasing(p=0.25),\n",
    "        torchvision.transforms.ToPILImage()\n",
    "    ]),\n",
    "    \n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    ]),\n",
    "    \n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Pad(4),                  # Padding\n",
    "        torchvision.transforms.RandomResizedCrop(32),  # 裁剪并resize\n",
    "    ]),\n",
    "    \n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),          # 随机水平翻转\n",
    "    ]),\n",
    "]\n",
    "\n",
    "# train_aug_config = [{},{},{},{\"mixup_alpha\":0.1},{\"cutmix_alpha\":1.0}]\n",
    "train_aug_config = [{},{},{},{},{}]\n",
    "if_aug_matrix = False\n",
    "aug_matrix_train_aug_combines = []\n",
    "aug_matrix_val_results = []\n",
    "if if_aug_matrix:\n",
    "    temp_aug_config = []\n",
    "    for i in range(len(train_augmentations)):\n",
    "        for j in range(len(train_augmentations)):\n",
    "            if i == j:\n",
    "                aug_matrix_train_aug_combines.append(torchvision.transforms.Compose([train_augmentations[i]]))\n",
    "            else:\n",
    "                aug_matrix_train_aug_combines.append(torchvision.transforms.Compose([train_augmentations[i],train_augmentations[j]]))\n",
    "            temp_aug_config.append(train_aug_config[i] | train_aug_config[j])\n",
    "    train_aug_config = temp_aug_config\n",
    "# 超参\n",
    "is_eval = True\n",
    "use_one_model = False\n",
    "\n",
    "num_epochs = 90\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "weight_decay = 0\n",
    "grad_clip  = 0\n",
    "save_bin_name = \"202501101029\"\n",
    "datasets = \"uoft-cs/cifar10\"\n",
    "datasets_image_column_name = \"img\"\n",
    "number_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pretrain_model_list = []\n",
    "model_list = []\n",
    "\n",
    "model_name1 = \"microsoft/resnet-50\"\n",
    "model1 = AutoModelForImageClassification.from_pretrained(model_name1, trust_remote_code=True)\n",
    "pretrain_model_list.append(model1)\n",
    "model_list.append(\"acc_best_model_202412300900.bin\")\n",
    "\n",
    "model_name2 = \"leftthomas/resnet50\"\n",
    "model2 = AutoModelForImageClassification.from_pretrained(model_name2, trust_remote_code=True)\n",
    "pretrain_model_list.append(model2)\n",
    "model_list.append(\"acc_best_model_202412301709.bin\")\n",
    "\n",
    "model3 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "pretrain_model_list.append(model3)\n",
    "model_list.append(\"acc_best_model_202501052203-0.bin\")\n",
    "\n",
    "model4 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "pretrain_model_list.append(model4)\n",
    "model_list.append(\"acc_best_model_202501052203-1.bin\")\n",
    "\n",
    "model5 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "pretrain_model_list.append(model5)\n",
    "model_list.append(\"acc_best_model_202412302006.bin\")\n",
    "\n",
    "if use_one_model:\n",
    "    number_models = len(pretrain_model_list)\n",
    "    pretrain_model_list = []\n",
    "    for i in range(number_models):\n",
    "        pretrain_model_list.append(model1)\n",
    "\n",
    "for i,model in enumerate(pretrain_model_list):\n",
    "\n",
    "    # 修改分类头\n",
    "    if not hasattr(model,\"fc\") and hasattr(model, \"classifier\"):\n",
    "        model.classifier = nn.Sequential(\n",
    "            model.classifier[0],\n",
    "            nn.Linear(in_features=2048, out_features=number_classes, bias=True)\n",
    "        )\n",
    "    elif hasattr(model, \"model\") and hasattr(model.model, \"fc\"):\n",
    "        model.model.fc = nn.Linear(in_features=2048, out_features=number_classes, bias=True)\n",
    "    elif hasattr(model,\"fc\"):\n",
    "        model.fc = nn.Linear(in_features=2048, out_features=number_classes, bias=True)\n",
    "    \n",
    "    model.to(device)\n",
    "    if is_eval:\n",
    "        model.load_state_dict(torch.load(model_list[i]))\n",
    "        print(f\"{i}th Model loaded from {model_list[i]}\")\n",
    "    \n",
    "\n",
    "use_adam = True\n",
    "\n",
    "use_sgd = False\n",
    "sgd_momentum = 0.9\n",
    "sgd_nesterov = False\n",
    "\n",
    "use_custom_scheduler = False\n",
    "custom_scheduler_gammas = [0.1, 0.01, 0.001, 0.0005]\n",
    "custom_scheduler_milestones = [80, 120,160,180]\n",
    "\n",
    "use_cosine_annealing = False\n",
    "\n",
    "use_onecyclelr = False\n",
    "\n",
    "use_reducelronplateau = False\n",
    "reducelronplateau_mode = \"max\"\n",
    "reducelronplateau_factor = 0.1\n",
    "reducelronplateau_patience = 3\n",
    "reducelronplateau_threshold = 0.001\n",
    "\n",
    "use_steplr = True\n",
    "steplr_step_size = 30\n",
    "steplr_gamma = 0.1\n",
    "\n",
    "\n",
    "test_augmentation_transforms = torchvision.transforms.Compose([\n",
    "    # torchvision.transforms.Pad(4),                                # Padding\n",
    "    # torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    # torchvision.transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    # torchvision.transforms.Resize((160,160)),\n",
    "    # torchvision.transforms.RandomCrop((128,128)),\n",
    "    # torchvision.transforms.RandomCrop(32),                       # 随机裁剪\n",
    "    # torchvision.transforms.RandomHorizontalFlip(p=0.5),          # 随机水平翻转\n",
    "    # torchvision.transforms.RandomResizedCrop(32),  # 裁剪并resize\n",
    "    # torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    # torchvision.transforms.Resize((int(32/0.95),int(32/0.95))),\n",
    "    # torchvision.transforms.CenterCrop((32, 32)),\n",
    "    # torchvision.transforms.RandomAdjustSharpness(2, p=0.5)\n",
    "    # torchvision.transforms.RandomCrop((32,32)),\n",
    "    # torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # torchvision.transforms.RandomCrop(32, padding=4),  # 随机裁剪\n",
    "])\n",
    "\n",
    "# pre_get_mean = [0.4214581847190857, 0.3764420747756958, 0.28500789403915405] \n",
    "# pre_get_std = [0.293678343296051, 0.24473334848880768, 0.27143558859825134]\n",
    "pre_get_mean = []\n",
    "pre_get_std = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\admin/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "Using cache found in C:\\Users\\admin/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "Using cache found in C:\\Users\\admin/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "C:\\Users\\admin/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_44044\\1250133390.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_list[i]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th Model loaded from acc_best_model_202412300900.bin\n",
      "1th Model loaded from acc_best_model_202412301709.bin\n",
      "2th Model loaded from acc_best_model_202501052203-0.bin\n",
      "3th Model loaded from acc_best_model_202501052203-1.bin\n",
      "4th Model loaded from acc_best_model_202412302006.bin\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T01:51:09.145399Z",
     "iopub.status.busy": "2024-12-28T01:51:09.144982Z",
     "iopub.status.idle": "2024-12-28T01:51:09.152443Z",
     "shell.execute_reply": "2024-12-28T01:51:09.151586Z",
     "shell.execute_reply.started": "2024-12-28T01:51:09.145366Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:10.747365Z",
     "start_time": "2025-01-11T08:54:10.743180Z"
    }
   },
   "source": [
    "def set_random_seed(seed):\n",
    "    \"\"\"\n",
    "    设置随机种子以确保实验的可重复性\n",
    "    \"\"\"\n",
    "    # 设置 PyTorch 的随机种子\n",
    "    torch.manual_seed(seed)\n",
    "    # 如果使用 GPU，也需要设置随机种子\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # 如果有多个 GPU\n",
    "    # 设置 NumPy 的随机种子\n",
    "    np.random.seed(seed)\n",
    "    # 设置 Python 内置的随机数生成器的种子\n",
    "    random.seed(seed)\n",
    "    # 确保 PyTorch 的随机性是可重复的\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # 关闭自动优化\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:11.203602Z",
     "start_time": "2025-01-11T08:54:11.197984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_mean_std(dataset, batch_size=1):\n",
    "    \"\"\"\n",
    "    动态计算数据集的均值和标准差，适用于任何数据集。\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): 目标数据集。\n",
    "        batch_size (int): 数据加载的批量大小（默认64）。\n",
    "    Returns:\n",
    "        mean (list): 每个通道的均值。\n",
    "        std (list): 每个通道的标准差。\n",
    "    \"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    # 用于存储累计的均值和方差\n",
    "    total_sum = 0.0\n",
    "    total_squared_sum = 0.0\n",
    "    total_pixels = 0\n",
    "    # 遍历数据集，计算总和和平方和\n",
    "    for images, _ in loader:\n",
    "        # 图像形状为 (batch_size, channels, height, width)\n",
    "        batch_samples = images.size(0)  # 当前批次的样本数量\n",
    "        pixels_per_image = images.size(2) * images.size(3)  # 每张图片的像素数\n",
    "        total_pixels += batch_samples * pixels_per_image\n",
    "        # 将图像展开为 (batch_size, channels, -1) 后求和\n",
    "        total_sum += images.sum(dim=[0, 2, 3])  # 每个通道的总和\n",
    "        total_squared_sum += (images ** 2).sum(dim=[0, 2, 3])  # 每个通道的平方和\n",
    "    # 计算均值和标准差\n",
    "    mean = total_sum / total_pixels\n",
    "    std = torch.sqrt((total_squared_sum / total_pixels) - (mean ** 2))\n",
    "    return mean.tolist(), std.tolist()\n"
   ],
   "id": "e49cd553101468a9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e42047861e8385fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T01:51:11.561644Z",
     "iopub.status.busy": "2024-12-28T01:51:11.561345Z",
     "iopub.status.idle": "2024-12-28T01:51:11.570420Z",
     "shell.execute_reply": "2024-12-28T01:51:11.569537Z",
     "shell.execute_reply.started": "2024-12-28T01:51:11.561622Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:11.584763Z",
     "start_time": "2025-01-11T08:54:11.574935Z"
    }
   },
   "source": [
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion, device, train_aug_config):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        if hasattr(train_aug_config,\"mixup_alpha\") or hasattr(train_aug_config,\"cutmix_alpha\"):\n",
    "            mixup_alpha = train_aug_config[\"mixup_alpha\"] if hasattr(train_aug_config,\"mixup_alpha\") else 0\n",
    "            cutmix_alpha = train_aug_config[\"cutmix_alpha\"] if hasattr(train_aug_config,\"cutmix_alpha\") else 0\n",
    "            # 初始化 Mixup\n",
    "            mixup_fn = timm.data.mixup.Mixup(\n",
    "                mixup_alpha= mixup_alpha,  # Mixup 的 alpha 参数\n",
    "                cutmix_alpha= cutmix_alpha, # 如果不使用 CutMix，可以将其设为 0\n",
    "                label_smoothing=0.0,  # 标签平滑，如果需要\n",
    "                num_classes=number_classes    # 数据集的类别数量\n",
    "            )\n",
    "            images, labels = mixup_fn(images, labels) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if hasattr(model(images), \"logits\"):\n",
    "                outputs = model(images).logits\n",
    "        elif isinstance(model(images), dict):\n",
    "            outputs = model(images)[\"logits\"]\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip != 0:\n",
    "            # 裁剪梯度的范数\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device, need_record=False):\n",
    "    \"\"\"\n",
    "    评估模型并记录所有样本的最大信心分数，同时区分正确分类和错误分类的样本。\n",
    "\n",
    "    Args:\n",
    "        model: 评估的模型。\n",
    "        data_loader: 数据加载器（测试集或验证集）。\n",
    "        criterion: 损失函数。\n",
    "        device: 设备（CPU/GPU）。\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: 平均损失。\n",
    "        accuracy: 准确率。\n",
    "        correct_confidences: 正确分类样本的最大信心分数列表。\n",
    "        wrong_confidences: 错误分类样本的最大信心分数列表。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    correct_confidences = []\n",
    "    wrong_confidences = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            if hasattr(model(images), \"logits\"):\n",
    "                outputs = model(images).logits\n",
    "            elif isinstance(model(images), dict):\n",
    "                outputs = model(images)[\"logits\"]\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            max_confidences, predicted = probabilities.max(1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            if need_record:\n",
    "                # 根据分类正确与否记录最大信心分数\n",
    "                for i in range(len(labels)):\n",
    "                    if predicted[i] == labels[i]:\n",
    "                        correct_confidences.append(max_confidences[i].item())\n",
    "                    else:\n",
    "                        wrong_confidences.append(max_confidences[i].item())\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    return total_loss / len(data_loader), accuracy, correct_confidences, wrong_confidences\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:11:36.692672Z",
     "start_time": "2025-01-11T12:11:36.683527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_remote_predict(image,test_mean,test_std):\n",
    "    \n",
    "    print(\"start request remote model.\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    image = image.cpu()\n",
    "    # 对图像进行反归一化\n",
    "    denormalized_image = denormalize(image.unsqueeze(0), test_mean, test_std).squeeze(0).clamp(0, 1)\n",
    "\n",
    "    # 转换图像为PIL格式并保存\n",
    "    transform = torchvision.transforms.ToPILImage()\n",
    "    pil_image = transform(denormalized_image)\n",
    "    \n",
    "    # 将PIL图像转换为字节流\n",
    "    image_bytes = io.BytesIO()\n",
    "    pil_image.save(image_bytes, format='PNG')\n",
    "    image_bytes.seek(0)\n",
    "    \n",
    "    client = OpenAI(\n",
    "            base_url= openai_api_rul,\n",
    "            api_key= openai_api_key,\n",
    "    )\n",
    "    \n",
    "    result = \"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"Please analyze the given image and determine which category it belongs to from the following list: Airplane, Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck. Respond with only the index number corresponding to the category, where the indexes are as follows: 0: Airplane; 1: Automobile; 2: Bird; 3: Cat; 4: Deer; 5: Dog; 6: Frog; 7: Horse; 8: Ship; 9: Truck. Provide ONLY the index number as your answer. DO NOT add more text.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\", \"text\": \"What is the category of the image? Please analyze the given image and determine which category it belongs to from the following list: Airplane, Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck. Respond with only the index number corresponding to the category, where the indexes are as follows: 0: Airplane; 1: Automobile; 2: Bird; 3: Cat; 4: Deer; 5: Dog; 6: Frog; 7: Horse; 8: Ship; 9: Truck. Provide ONLY the index number as your answer. DO NOT add more text.\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpg;base64,{base64.b64encode(image_bytes.read()).decode('utf-8')}\"},\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    while True:  # 无限循环直到成功\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                model=\"gpt-4o\",\n",
    "            )\n",
    "            print(chat_completion.choices[0].message.content)\n",
    "            result = chat_completion.choices[0].message.content\n",
    "            break  # 如果请求成功，退出循环\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "            if \"Cloudflare\" not in error:\n",
    "                # 如果不是 Cloudflare 错误，直接打印并退出\n",
    "                print(error)\n",
    "                break\n",
    "            else:\n",
    "                # 如果是 Cloudflare 错误，等待 3 秒后重试\n",
    "                print(\"遇到 Cloudflare 错误，等待 3 秒后重试...\")\n",
    "                time.sleep(3)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = (end_time - start_time).total_seconds()\n",
    "    print(f\"请求远程模型花费时间: {elapsed_time} 秒\")\n",
    "    return result, elapsed_time"
   ],
   "id": "1fc9403401facad8",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:01:18.164842Z",
     "start_time": "2025-01-11T10:01:18.154973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ensemble_evaluate_model(ensemble_model_list, data_loader, criterion, device,need_record=False, remote_threshold=1.0,test_mean=None,test_std=None):\n",
    "    for model in ensemble_model_list:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confidences = []\n",
    "    is_correct = []\n",
    "    total_time = 0\n",
    "    local_predict_time = 0\n",
    "    remote_predict_time = 0\n",
    "    remote_predict_count = 0\n",
    "    remote_reject_count = 0\n",
    "    remote_correct_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output_list = []\n",
    "            start_time = datetime.now()\n",
    "            for model in ensemble_model_list:\n",
    "                if hasattr(model(images), \"logits\"):\n",
    "                    outputs = model(images).logits\n",
    "                elif isinstance(model(images), dict):\n",
    "                    outputs = model(images)[\"logits\"]\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                output_list.append(outputs)\n",
    "            stacked_outputs = torch.stack(output_list)\n",
    "            outputs = torch.mean(stacked_outputs, dim=0)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            max_confidences, predicted = probabilities.max(1)\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            elapsed_time = (end_time - start_time).total_seconds()\n",
    "            total_time += elapsed_time\n",
    "            local_predict_time += elapsed_time\n",
    "            if 0.0 <= remote_threshold <= 1.0:\n",
    "                masks = max_confidences < remote_threshold\n",
    "                for i,mask in enumerate(masks):\n",
    "                    if mask:\n",
    "                        remote_predict,time_spend = get_remote_predict(images[i],test_mean,test_std)\n",
    "                        remote_predict_time += time_spend\n",
    "                        total_time += time_spend\n",
    "                        remote_predict_count += 1\n",
    "                        try:\n",
    "                            predicted[i] = int(remote_predict)\n",
    "                            if predicted[i] == labels[i]:\n",
    "                                remote_correct_count += 1\n",
    "                        except Exception as e:\n",
    "                            remote_reject_count += 1\n",
    "                            remote_predict_count -= 1\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            if need_record:\n",
    "                # 保存置信度和分类正确性\n",
    "                confidences.extend(max_confidences.cpu().numpy())\n",
    "                is_correct.extend(predicted.eq(labels).cpu().numpy())\n",
    "\n",
    "    print(\"total avg time:\",total_time/len(data_loader.dataset))        \n",
    "    print(\"total count:\",len(data_loader.dataset))\n",
    "    print(\"local avg time:\",local_predict_time/len(data_loader.dataset))    \n",
    "    if remote_predict_count+remote_reject_count > 0:\n",
    "        print(\"remote avg time:\",remote_predict_time/(remote_predict_count+remote_reject_count))\n",
    "    print(\"remote_predict_count:\",remote_predict_count)\n",
    "    print(\"remote_reject_count:\",remote_reject_count)\n",
    "    print(\"remote_correct_count:\",remote_correct_count)\n",
    "    print(\"total correct:\", correct)\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    return total_loss / len(data_loader), accuracy, np.array(confidences), np.array(is_correct)\n"
   ],
   "id": "39f159aa7c3a41cb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:13.668035Z",
     "start_time": "2025-01-11T08:54:13.664298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_image(path,name,image,test_mean,test_std):\n",
    "    image = image.cpu()\n",
    "    # 对图像进行反归一化\n",
    "    denormalized_image = denormalize(image.unsqueeze(0), test_mean, test_std).squeeze(0).clamp(0, 1)\n",
    "\n",
    "    # 转换图像为PIL格式并保存\n",
    "    transform = torchvision.transforms.ToPILImage()\n",
    "    pil_image = transform(denormalized_image)\n",
    "    save_path = path\n",
    "    save_name = name\n",
    "    pil_image.save(save_path+\"/\"+save_name)"
   ],
   "id": "9123526c81d60c27",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "9f66fa45ba7ad354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T01:51:14.011543Z",
     "iopub.status.busy": "2024-12-28T01:51:14.011256Z",
     "iopub.status.idle": "2024-12-28T01:51:14.019398Z",
     "shell.execute_reply": "2024-12-28T01:51:14.018513Z",
     "shell.execute_reply.started": "2024-12-28T01:51:14.011520Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:14.218549Z",
     "start_time": "2025-01-11T08:54:14.212448Z"
    }
   },
   "source": [
    "def get_dataloaders(augmentation_transforms,val_augmentation_transforms, batch_size=128):\n",
    "    # Load dataset from Hugging Face\n",
    "    dataset = load_dataset(datasets)\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),  # 将 PIL.Image 转换为 Tensor\n",
    "    ])\n",
    "\n",
    "    # 定义训练集和验证集的划分比例\n",
    "    train_size = int(0.8 * len(dataset['train']))  # 80% 作为训练集\n",
    "    val_size = len(dataset['train']) - train_size  # 剩下的作为验证集\n",
    "    train_subset, val_subset = random_split(dataset['train'], [train_size, val_size])\n",
    "\n",
    "    # 转换为 Tensor 格式\n",
    "    train_dataset = [(transform(item[datasets_image_column_name].convert(\"RGB\")), item[\"label\"]) for item in train_subset]\n",
    " \n",
    "    if len(pre_get_mean) > 0 and len(pre_get_std) > 0:\n",
    "        mean = pre_get_mean\n",
    "        std = pre_get_std\n",
    "    else:\n",
    "        # **只使用训练集计算均值和标准差**\n",
    "        mean, std = calculate_mean_std(train_dataset)\n",
    "        print(\"Train dataset mean and std:\", mean, std)\n",
    "\n",
    "    # 定义训练集的 transform（包括数据增强）\n",
    "    train_transform = torchvision.transforms.Compose([\n",
    "        augmentation_transforms,\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "    # 验证集和测试集的 transform（不包括数据增强）\n",
    "    eval_transform = torchvision.transforms.Compose([\n",
    "        val_augmentation_transforms,\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "    # 应用 transforms\n",
    "    train_dataset = [(train_transform(item[datasets_image_column_name].convert(\"RGB\")), item[\"label\"]) for item in train_subset]\n",
    "    val_dataset = [(eval_transform(item[datasets_image_column_name].convert(\"RGB\")), item[\"label\"]) for item in val_subset]\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:14.714188Z",
     "start_time": "2025-01-11T08:54:14.708452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_test_loader(test_augmentation_transforms, batch_size=128,size=10000):\n",
    "    \n",
    "    # Load dataset from Hugging Face\n",
    "    dataset = load_dataset(datasets)\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),  # 将 PIL.Image 转换为 Tensor\n",
    "    ])\n",
    "\n",
    "    # 定义训练集和验证集的划分比例\n",
    "    train_size = int(0.8 * len(dataset['train']))  # 80% 作为训练集\n",
    "    val_size = len(dataset['train']) - train_size  # 剩下的作为验证集\n",
    "    train_subset, val_subset = random_split(dataset['train'], [train_size, val_size])\n",
    "\n",
    "    # 转换为 Tensor 格式\n",
    "    train_dataset = [(transform(item[datasets_image_column_name].convert(\"RGB\")), item[\"label\"]) for item in train_subset]\n",
    " \n",
    "    if len(pre_get_mean) > 0 and len(pre_get_std) > 0:\n",
    "        mean = pre_get_mean\n",
    "        std = pre_get_std\n",
    "    else:\n",
    "        # **只使用训练集计算均值和标准差**\n",
    "        mean, std = calculate_mean_std(train_dataset)\n",
    "        print(\"Train dataset mean and std:\", mean, std)\n",
    "\n",
    "    # 验证集和测试集的 transform（不包括数据增强）\n",
    "    eval_transform = torchvision.transforms.Compose([\n",
    "        test_augmentation_transforms,\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "    test_dataset = [(eval_transform(item[datasets_image_column_name].convert(\"RGB\")), item[\"label\"]) for item in dataset[\"test\"]]\n",
    "    \n",
    "    if size > len(test_dataset):\n",
    "        raise ValueError(\"测试集子集大小不能超过测试集大小\")\n",
    "    \n",
    "    subset_indices = random.sample(range(len(test_dataset)), size)\n",
    "    \n",
    "    test_subset = Subset(test_dataset, subset_indices)\n",
    "\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return test_loader, mean, std"
   ],
   "id": "e1b245bb70042ca8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:15.349975Z",
     "start_time": "2025-01-11T08:54:15.345532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_confidences(correct_confidences, wrong_confidences):\n",
    "    \"\"\"\n",
    "    可视化正确分类样本和错误分类样本的最大信心分数。\n",
    "\n",
    "    Args:\n",
    "        correct_confidences: 正确分类样本的最大信心分数列表。\n",
    "        wrong_confidences: 错误分类样本的最大信心分数列表。\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(number_classes, 6))\n",
    "    plt.hist(correct_confidences, bins=50, alpha=0.7, label='Correctly Classified', color='green')\n",
    "    plt.hist(wrong_confidences, bins=50, alpha=0.7, label='Misclassified', color='orange')\n",
    "    plt.xlabel('Maximum Confidence Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Confidence Distribution of Correct and Wrong Classifications')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "b5682dc4acd5d2be",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:15.747717Z",
     "start_time": "2025-01-11T08:54:15.742593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomMultiStepLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, milestones, gammas, last_epoch=-1):\n",
    "        self.milestones = milestones\n",
    "        self.gammas = gammas\n",
    "        assert len(milestones) == len(gammas), \"Milestones and gammas must have the same length\"\n",
    "        super(CustomMultiStepLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        factor = 1.0\n",
    "        for milestone, gamma in zip(self.milestones, self.gammas):\n",
    "            if self.last_epoch >= milestone:\n",
    "                factor = gamma  # 只应用当前 milestone 的 gamma\n",
    "        return [base_lr * factor for base_lr in self.base_lrs]"
   ],
   "id": "4f5ba3ef8f60c1e6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:16.323275Z",
     "start_time": "2025-01-11T08:54:16.319619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义反归一化函数\n",
    "def denormalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    将归一化的张量还原为原始像素值范围\n",
    "    :param tensor: 标准化后的张量\n",
    "    :param mean: 均值\n",
    "    :param std: 标准差\n",
    "    :return: 非归一化的张量\n",
    "    \"\"\"\n",
    "    mean = torch.tensor(mean).view(1, -1, 1, 1)\n",
    "    std = torch.tensor(std).view(1, -1, 1, 1)\n",
    "    return tensor * std + mean"
   ],
   "id": "3b5996b43e20441f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:16.718615Z",
     "start_time": "2025-01-11T08:54:16.710699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_confidence_accuracy_and_ece(confidences, is_correct, num_bins=10):\n",
    "    \"\"\"\n",
    "    绘制置信度与准确率、样本数量的关系曲线，并计算 ECE\n",
    "    :param confidences: 每个样本的最大置信度\n",
    "    :param is_correct: 每个样本的分类正确性 (1: 正确, 0: 错误)\n",
    "    :param num_bins: 分箱数量，用于 ECE 计算\n",
    "    \"\"\"\n",
    "    thresholds = np.linspace(0.0, 1.0, 50)  # 设置不同的置信度阈值\n",
    "    accuracies = []\n",
    "    sample_counts = []\n",
    "\n",
    "    for tau in thresholds:\n",
    "        mask = confidences >= tau  # 筛选置信度大于 tau 的样本\n",
    "        if mask.sum() > 0:  # 如果筛选后的样本数大于0\n",
    "            accuracy = is_correct[mask].mean()  # 计算准确率\n",
    "        else:\n",
    "            accuracy = 0.0  # 无样本时准确率为0\n",
    "        accuracies.append(accuracy)\n",
    "        sample_counts.append(mask.sum())\n",
    "    \n",
    "    # 计算 ECE\n",
    "    bin_boundaries = np.linspace(0.0, 1.0, num_bins + 1)  # 分箱边界\n",
    "    ece = 0.0\n",
    "    bin_accuracies = []\n",
    "    bin_confidences = []\n",
    "    bin_sample_counts = []\n",
    "\n",
    "    for i in range(num_bins):\n",
    "        bin_lower = bin_boundaries[i]\n",
    "        bin_upper = bin_boundaries[i + 1]\n",
    "        bin_mask = (confidences > bin_lower) & (confidences <= bin_upper)\n",
    "        bin_size = bin_mask.sum()\n",
    "\n",
    "        if bin_size > 0:\n",
    "            bin_accuracy = is_correct[bin_mask].mean()\n",
    "            bin_confidence = confidences[bin_mask].mean()\n",
    "            ece += (bin_size / len(confidences)) * abs(bin_accuracy - bin_confidence)\n",
    "\n",
    "            bin_accuracies.append(bin_accuracy)\n",
    "            bin_confidences.append(bin_confidence)\n",
    "            bin_sample_counts.append(bin_size)\n",
    "        else:\n",
    "            bin_accuracies.append(0.0)\n",
    "            bin_confidences.append(0.0)\n",
    "            bin_sample_counts.append(0)\n",
    "\n",
    "    # 绘制曲线\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # 绘制准确率和样本数量曲线\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(thresholds, accuracies, label=\"Accuracy vs. Confidence Threshold\", color=\"b\")\n",
    "    plt.xlabel(\"Confidence Threshold (τ)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs. Confidence Threshold\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(thresholds, sample_counts, label=\"Sample Count vs. Confidence Threshold\", color=\"g\")\n",
    "    plt.xlabel(\"Confidence Threshold (τ)\")\n",
    "    plt.ylabel(\"Sample Count\")\n",
    "    plt.title(\"Sample Count vs. Confidence Threshold\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return ece, bin_accuracies, bin_confidences, bin_sample_counts\n"
   ],
   "id": "cf1a32c89cfe9c76",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T08:54:17.318136Z",
     "start_time": "2025-01-11T08:54:17.310983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_score_vs_threshold(confidences, is_correct, alpha=0.5, beta=0.5):\n",
    "    \"\"\"\n",
    "    计算不同置信度阈值下的准确率、覆盖率和得分\n",
    "    :param confidences: 每个样本的最大置信度\n",
    "    :param is_correct: 每个样本的分类正确性 (1: 正确, 0: 错误)\n",
    "    :param alpha: 准确率的权重\n",
    "    :param beta: 覆盖率的权重\n",
    "    :return: thresholds, accuracies, coverages, scores\n",
    "    \"\"\"\n",
    "    thresholds = np.linspace(0.0, 1.0, 50)\n",
    "    accuracies = []\n",
    "    coverages = []\n",
    "    scores = []\n",
    "\n",
    "    total_samples = len(confidences)\n",
    "\n",
    "    for tau in thresholds:\n",
    "        mask = confidences >= tau\n",
    "        \n",
    "        if mask.sum() > 0:\n",
    "            accuracy = is_correct[mask].mean()  # 准确率\n",
    "            coverage = mask.sum() / total_samples  # 覆盖率\n",
    "        else:\n",
    "            accuracy = 0.0\n",
    "            coverage = 0.0\n",
    "        \n",
    "        if alpha + beta > 1.0:\n",
    "            beta = 1 - alpha\n",
    "            if beta >= 0 and beta <= 1.0:\n",
    "                print(f\"beta has been justified to {beta}\")\n",
    "            else:\n",
    "                alpha = 0.5\n",
    "                beta = 0.5\n",
    "                print(f\"alpha has been justified to {alpha}\")\n",
    "                print(f\"beta has been justified to {beta}\")\n",
    "        \n",
    "        gamma = 1 - alpha - beta\n",
    "        \n",
    "        # 计算得分\n",
    "        score  = alpha * accuracy + beta * coverage + gamma * accuracy * coverage\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        coverages.append(coverage)\n",
    "        scores.append(score)\n",
    "    \n",
    "    best_score_index = scores.index(max(scores))\n",
    "    print(\"Threshold of the best score:\", thresholds[best_score_index])\n",
    "    print(\"Accuracy of the best score:\", accuracies[best_score_index])\n",
    "    print(\"Coverage of the best score:\", coverages[best_score_index])\n",
    "    return thresholds, accuracies, coverages, scores\n",
    "\n",
    "def plot_score_vs_threshold(thresholds, accuracies, coverages, scores):\n",
    "    \"\"\"\n",
    "    绘制准确率、覆盖率和得分随置信度阈值变化的曲线\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    plt.plot(thresholds, coverages, label=\"Coverage\", color=\"green\")\n",
    "    plt.plot(thresholds, scores, label=\"Score\", color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Confidence Threshold (τ)\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Accuracy, Coverage, and Score vs. Confidence Threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "fb55fe207ed6ca71",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "17fa70a2f801f5c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T01:51:18.970073Z",
     "iopub.status.busy": "2024-12-28T01:51:18.969712Z",
     "iopub.status.idle": "2024-12-28T01:52:22.424961Z",
     "shell.execute_reply": "2024-12-28T01:52:22.424215Z",
     "shell.execute_reply.started": "2024-12-28T01:51:18.970036Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T10:02:44.113505Z",
     "start_time": "2025-01-11T10:01:43.977641Z"
    }
   },
   "source": [
    "train_loader_list = []\n",
    "val_loader_list = []\n",
    "\n",
    "set_random_seed(eval_seed)\n",
    "test_loader,test_mean,test_std = get_test_loader(test_augmentation_transforms, batch_size=batch_size, size=1000)\n",
    "    \n",
    "if not is_eval:\n",
    "    for i,model in enumerate(pretrain_model_list):\n",
    "        set_random_seed(seeds[i])\n",
    "        if if_aug_matrix:\n",
    "            for j in range(len(aug_matrix_train_aug_combines)):\n",
    "                print(f\"aug:{aug_matrix_train_aug_combines[j]}\")\n",
    "                train_loader, val_loader = get_dataloaders(aug_matrix_train_aug_combines[j],test_augmentation_transforms,batch_size)\n",
    "                train_loader_list.append(train_loader)\n",
    "                val_loader_list.append(val_loader)\n",
    "        else:\n",
    "            train_loader, val_loader = get_dataloaders(train_augmentations[i],test_augmentation_transforms,batch_size)\n",
    "            train_loader_list.append(train_loader)\n",
    "            val_loader_list.append(val_loader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset mean and std: [0.4917724132537842, 0.4823954701423645, 0.44665318727493286] [0.24700681865215302, 0.24335941672325134, 0.2616914212703705]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "28579f8356786d6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T01:52:38.245785Z",
     "iopub.status.busy": "2024-12-28T01:52:38.245504Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T08:55:39.444093Z",
     "start_time": "2025-01-11T08:55:39.435582Z"
    }
   },
   "source": [
    "if not is_eval:\n",
    "    for i,model in enumerate(pretrain_model_list):\n",
    "        original_state = copy.deepcopy(model.state_dict())\n",
    "        aug_times = 1\n",
    "        if if_aug_matrix and len(aug_matrix_train_aug_combines)>0:\n",
    "            aug_times = len(aug_matrix_train_aug_combines)\n",
    "        for j in range(aug_times):\n",
    "            set_random_seed(seeds[i])\n",
    "            best_val_loss = float('inf')\n",
    "            loss_best_model = None\n",
    "            best_val_acc = 0\n",
    "            acc_best_model = None\n",
    "            \n",
    "            if use_adam:\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "            elif use_sgd:\n",
    "                optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=sgd_momentum, weight_decay=weight_decay, nesterov=sgd_nesterov)\n",
    "            else:\n",
    "                optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "                \n",
    "            if use_custom_scheduler:\n",
    "                scheduler = CustomMultiStepLR(optimizer, custom_scheduler_milestones, custom_scheduler_gammas)\n",
    "            elif use_cosine_annealing:\n",
    "                scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "            elif use_onecyclelr:\n",
    "                scheduler = OneCycleLR(optimizer, learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader_list[i]))\n",
    "            elif use_reducelronplateau:\n",
    "                scheduler = ReduceLROnPlateau(optimizer, mode=reducelronplateau_mode, factor=reducelronplateau_factor, patience=reducelronplateau_patience, threshold=reducelronplateau_threshold)\n",
    "            elif use_steplr:\n",
    "                scheduler = StepLR(optimizer, step_size=steplr_step_size, gamma=steplr_gamma)\n",
    "            else:\n",
    "                scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "            \n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "                train_loss = train(model, train_loader_list[i*aug_times+j], optimizer, criterion, device, train_aug_config[i*aug_times+j])\n",
    "                val_loss, val_accuracy,_,_ = evaluate_model(model, val_loader_list[i*aug_times+j], criterion, device, need_record=False)\n",
    "                \n",
    "                if(val_loss <= best_val_loss):\n",
    "                    best_val_loss = val_loss\n",
    "                    loss_best_model = model.state_dict()\n",
    "                    torch.save(loss_best_model, \"loss_best_model_\"+save_bin_name+\"-\"+str(i*aug_times+j)+\".bin\")\n",
    "                    print(f\"val loss best model saved, best_val_loss: {best_val_loss}\")\n",
    "                if(val_accuracy > best_val_acc):\n",
    "                    best_val_acc = val_accuracy\n",
    "                    acc_best_model = model.state_dict()\n",
    "                    torch.save(acc_best_model, \"acc_best_model_\"+save_bin_name+\"-\"+str(i*aug_times+j)+\".bin\")\n",
    "                    print(f\"val accuracy best model saved, best_val_acc: {best_val_acc}\")\n",
    "                print(f\"Train Loss: {train_loss:.4f}, val Loss: {val_loss:.4f}, val Accuracy: {val_accuracy:.2f}%\")\n",
    "                if use_reducelronplateau:\n",
    "                    scheduler.step(metrics=val_accuracy)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            if if_aug_matrix and len(aug_matrix_train_aug_combines)>0:\n",
    "                aug_matrix_val_results.append(best_val_acc)\n",
    "                print(aug_matrix_val_results)\n",
    "                model.load_state_dict(original_state)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:12:14.567945Z",
     "start_time": "2025-01-11T12:11:47.779590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if is_eval:\n",
    "    set_random_seed(eval_seed)\n",
    "    test_loss, test_accuracy, confidences, is_correct = ensemble_evaluate_model(pretrain_model_list,test_loader, criterion, device, need_record=True,remote_threshold=0.9796,test_mean=test_mean, test_std=test_std)\n",
    "    \n",
    "    print(f\"test_loss: {test_loss}, test_accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # 绘制曲线并计算 ECE\n",
    "    ece, bin_accuracies, bin_confidences, bin_sample_counts = plot_confidence_accuracy_and_ece(confidences, is_correct, num_bins=10)\n",
    "    \n",
    "    # 输出 ECE 信息\n",
    "    print(f\"Expected Calibration Error (ECE): {ece:.4f}\")\n",
    "    \n",
    "    # 打印分箱详细信息\n",
    "    print(\"\\nBin Information:\")\n",
    "    for i, (acc, conf, count) in enumerate(zip(bin_accuracies, bin_confidences, bin_sample_counts)):\n",
    "        print(f\"Bin {i + 1}: Accuracy = {acc:.4f}, Confidence = {conf:.4f}, Samples = {count}\")\n",
    "    \n",
    "\n",
    "    # 计算不同阈值下的准确率、覆盖率和得分\n",
    "    thresholds, accuracies, coverages, scores = evaluate_score_vs_threshold(\n",
    "        confidences, is_correct, alpha=0.8, beta=0.1\n",
    "    )\n",
    "    \n",
    "    # 绘制曲线\n",
    "    plot_score_vs_threshold(thresholds, accuracies, coverages, scores)"
   ],
   "id": "a62a6072238912ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start request remote model.\n",
      "**Category:** Animal \n",
      "\n",
      "请求远程模型花费时间: 6.214716 秒\n",
      "start request remote model.\n",
      "I currently cannot view or analyze images directly. However, if you can describe the image to me, I'd be happy to help you determine which category it belongs to!\n",
      "请求远程模型花费时间: 2.828109 秒\n",
      "start request remote model.\n",
      "**Image Category:**\n",
      "\n",
      "* The image appears to be of a **skull**. \n",
      "\n",
      "请求远程模型花费时间: 2.141016 秒\n",
      "start request remote model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_eval:\n\u001B[0;32m      2\u001B[0m     set_random_seed(eval_seed)\n\u001B[1;32m----> 3\u001B[0m     test_loss, test_accuracy, confidences, is_correct \u001B[38;5;241m=\u001B[39m \u001B[43mensemble_evaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrain_model_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneed_record\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43mremote_threshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.9796\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mtest_mean\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_std\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_std\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_loss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, test_accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_accuracy\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# 绘制曲线并计算 ECE\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[29], line 47\u001B[0m, in \u001B[0;36mensemble_evaluate_model\u001B[1;34m(ensemble_model_list, data_loader, criterion, device, need_record, remote_threshold, test_mean, test_std)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i,mask \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(masks):\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mask:\n\u001B[1;32m---> 47\u001B[0m         remote_predict,time_spend \u001B[38;5;241m=\u001B[39m \u001B[43mget_remote_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_std\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m         remote_predict_time \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m time_spend\n\u001B[0;32m     49\u001B[0m         total_time \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m time_spend\n",
      "Cell \u001B[1;32mIn[44], line 47\u001B[0m, in \u001B[0;36mget_remote_predict\u001B[1;34m(image, test_mean, test_std)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:  \u001B[38;5;66;03m# 无限循环直到成功\u001B[39;00m\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 47\u001B[0m         chat_completion \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-4o\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m         \u001B[38;5;28mprint\u001B[39m(chat_completion\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent)\n\u001B[0;32m     52\u001B[0m         result \u001B[38;5;241m=\u001B[39m chat_completion\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    277\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[1;32m--> 279\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:859\u001B[0m, in \u001B[0;36mCompletions.create\u001B[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    818\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    819\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    856\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m    857\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m    858\u001B[0m     validate_response_format(response_format)\n\u001B[1;32m--> 859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m    863\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    864\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    866\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    867\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    868\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_completion_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    872\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    873\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodalities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreasoning_effort\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    883\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    885\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    886\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    887\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    888\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    889\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    895\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    898\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    899\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    901\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    902\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\openai\\_base_client.py:1280\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1266\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1267\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1268\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1275\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1276\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1277\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1278\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1279\u001B[0m     )\n\u001B[1;32m-> 1280\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\openai\\_base_client.py:957\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    954\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    955\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 957\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    962\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    963\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\openai\\_base_client.py:993\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[0;32m    990\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSending HTTP Request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, request\u001B[38;5;241m.\u001B[39mmethod, request\u001B[38;5;241m.\u001B[39murl)\n\u001B[0;32m    992\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 993\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    994\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    995\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_should_stream_response_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    996\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    997\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    998\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    999\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered httpx.TimeoutException\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpx\\_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[1;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[0;32m    910\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_timeout(request)\n\u001B[0;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[1;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    921\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpx\\_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[1;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[0;32m    939\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[0;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    948\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpx\\_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[1;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    977\u001B[0m     hook(request)\n\u001B[1;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    981\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpx\\_client.py:1014\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m   1009\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1010\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1011\u001B[0m     )\n\u001B[0;32m   1013\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[1;32m-> 1014\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[0;32m   1018\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    237\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[0;32m    238\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    239\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    247\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    248\u001B[0m )\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[1;32m--> 250\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[0;32m    255\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mstatus,\n\u001B[0;32m    256\u001B[0m     headers\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    257\u001B[0m     stream\u001B[38;5;241m=\u001B[39mResponseStream(resp\u001B[38;5;241m.\u001B[39mstream),\n\u001B[0;32m    258\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    259\u001B[0m )\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    213\u001B[0m         closing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_requests_to_connections()\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_connections(closing)\n\u001B[1;32m--> 216\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, Iterable)\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    192\u001B[0m connection \u001B[38;5;241m=\u001B[39m pool_request\u001B[38;5;241m.\u001B[39mwait_for_connection(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[1;32m--> 196\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[0;32m    204\u001B[0m     pool_request\u001B[38;5;241m.\u001B[39mclear_connection()\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m--> 101\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_closed\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_closed()\n\u001B[1;32m--> 143\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs\n\u001B[0;32m    106\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m    107\u001B[0m     (\n\u001B[0;32m    108\u001B[0m         http_version,\n\u001B[0;32m    109\u001B[0m         status,\n\u001B[0;32m    110\u001B[0m         reason_phrase,\n\u001B[0;32m    111\u001B[0m         headers,\n\u001B[0;32m    112\u001B[0m         trailing_data,\n\u001B[1;32m--> 113\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    115\u001B[0m         http_version,\n\u001B[0;32m    116\u001B[0m         status,\n\u001B[0;32m    117\u001B[0m         reason_phrase,\n\u001B[0;32m    118\u001B[0m         headers,\n\u001B[0;32m    119\u001B[0m     )\n\u001B[0;32m    121\u001B[0m network_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_stream\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_headers\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    183\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 186\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mResponse):\n\u001B[0;32m    188\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    221\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[1;32m--> 224\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_network_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[1;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[1;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\ssl.py:1295\u001B[0m, in \u001B[0;36mSSLSocket.recv\u001B[1;34m(self, buflen, flags)\u001B[0m\n\u001B[0;32m   1291\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1292\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1293\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1294\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1295\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuflen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1296\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1297\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv(buflen, flags)\n",
      "File \u001B[1;32mC:\\Program Files\\miniconda3\\envs\\py311_torch\\Lib\\ssl.py:1168\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1166\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[0;32m   1167\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1168\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1169\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SSLError \u001B[38;5;28;01mas\u001B[39;00m x:\n\u001B[0;32m   1170\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m SSL_ERROR_EOF \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuppress_ragged_eofs:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set_random_seed(eval_seed)\n",
    "# for i,model in enumerate(pretrain_model_list):\n",
    "#     global_correct_confidences = []\n",
    "#     global_wrong_confidences = []\n",
    "#     test_loss, test_accuracy, correct_confidences, wrong_confidences = evaluate_model(model, test_loader, criterion, device, need_record=True)\n",
    "#     global_correct_confidences.extend(correct_confidences)\n",
    "#     global_wrong_confidences.extend(wrong_confidences)\n",
    "#     print(f\"test_loss: {test_loss}, test_accuracy: {test_accuracy}\")\n",
    "#     visualize_confidences(global_correct_confidences, global_wrong_confidences)"
   ],
   "id": "2916c828c2f5075f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0c263525b63dc42",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# set_random_seed(eval_seed)\n",
    "# for i,model in enumerate(pretrain_model_list):\n",
    "#     global_correct_confidences = []\n",
    "#     global_wrong_confidences = []\n",
    "#     model.load_state_dict(torch.load(\"loss_best_model_\"+save_bin_name+\"-\"+str(i)+\".bin\"))\n",
    "#     test_loss, test_accuracy, correct_confidences, wrong_confidences = evaluate_model(model, test_loader, criterion, device, need_record=True)\n",
    "#     global_correct_confidences.extend(correct_confidences)\n",
    "#     global_wrong_confidences.extend(wrong_confidences)\n",
    "#     print(f\"test_loss: {test_loss}, test_accuracy: {test_accuracy}\")\n",
    "#     visualize_confidences(global_correct_confidences, global_wrong_confidences)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set_random_seed(eval_seed)\n",
    "# for i,model in enumerate(pretrain_model_list):\n",
    "#     global_correct_confidences = []\n",
    "#     global_wrong_confidences = []\n",
    "#     model.load_state_dict(torch.load(\"acc_best_model_\"+save_bin_name+\"-\"+str(i)+\".bin\"))\n",
    "#     test_loss, test_accuracy, correct_confidences, wrong_confidences = evaluate_model(model, test_loader, criterion, device, need_record=True)\n",
    "#     global_correct_confidences.extend(correct_confidences)\n",
    "#     global_wrong_confidences.extend(wrong_confidences)\n",
    "#     print(f\"test_loss: {test_loss}, test_accuracy: {test_accuracy}\")\n",
    "#     visualize_confidences(global_correct_confidences, global_wrong_confidences)"
   ],
   "id": "146b657f46476da4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
